{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1 0.20.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/askming/GitHub/PythonDataScienceHandbook/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(np.__version__, pd.__version__)\n",
    "\n",
    "os.get_exec_path()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 4 5]]\n",
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  3  4  5\n"
     ]
    }
   ],
   "source": [
    "A = np.array([1,2,3,3,4, 5]).reshape(2,3)\n",
    "print(A)\n",
    "\n",
    "B = pd.DataFrame(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'import numpy as np\\nimport pandas as pd', 'import numpy as np\\nimport pandas as pd\\n\\nprint np.__version__', 'import numpy as np\\nimport pandas as pd\\n\\nprint(np.__version__, pd.__version__)', 'A = np.array([1,2,3,3,4, 5], shape = (2,3))\\nprint(A)', 'A = np.array([1,2,3,3,4, 5])\\nprint(A)', 'A = np.array([1,2,3,3,4, 5]).reshape(2,3)\\nprint(A)', 'A = np.array([1,2,3,3,4, 5]).reshape(2,3)\\nprint(A)\\n\\nA = A.dtype({\"name\":(\\'a\\', \\'b\\', \\'c\\')})', 'A = np.array([1,2,3,3,4, 5]).reshape(2,3)\\nprint(A)\\n\\nB = pd.DataFrame(A)\\nprint(B)', 'Print(In)', 'print(In)', 'print(In)\\nprint(len(Out))']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(In)\n",
    "print(len(Out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 6)\n",
      "[nan '/ild exacerbation vs decompensating chf'\n",
      " '? ild exacerbation vs decompensating chf'\n",
      " '?ild exacerbation vs decompensating chf'\n",
      " '?ild exacerbation vs decopensating chf' '?ild flare' '?mild ipf flare'\n",
      " 'acute exacerbation' 'acute exacerbation of ipf' 'airway tight'\n",
      " 'alveolar hemorrage/ild exacerbation' 'arthritis'\n",
      " 'aveolar hemorrage/ild exacerbation' 'breathlessness on exertion'\n",
      " 'chest infection' 'chronic hypoxy' 'comfort' 'conditioning' 'copd'\n",
      " 'copd +/- mild ipf flare?' 'copd/ipf' 'cough' 'coughing'\n",
      " 'decline in lung function' 'decreased o2 sats on exertion'\n",
      " 'decreased o2 saturations'\n",
      " 'decreased o2 saturations o/e and increased sob'\n",
      " 'decreased o2 saturations on minimal activity'\n",
      " 'decreased oxygen saturation on exertion' 'desaturation'\n",
      " 'drecreased o2 saturations on exertion' 'dyspnea'\n",
      " 'dyspnea decreased o2 sats on exertion'\n",
      " 'dyspnea decreased o2 saturations' 'dyspnea decreased o2 saturations o/e'\n",
      " 'dyspnea decreased o2 saturations on exertion' 'dyspnea increased'\n",
      " 'dyspnea on exertion' 'dyspnea post pulmonary embolism'\n",
      " 'dyspnea sleep apnea' 'dyspnea, acute exacerbation of ipf'\n",
      " 'dyspnea. decreased o2 saturations'\n",
      " 'dyspnea. decreased o2 saturations on exertion'\n",
      " 'dyspnea/ decreased o2 sats on exertion'\n",
      " 'dyspnea/ decreased o2 saturations '\n",
      " 'dyspnea/ decreased o2 saturations on exertion'\n",
      " 'dyspnea/ drcreased o2 saturation on exertion'\n",
      " 'dyspnea/decreased o2 sats' 'dyspnea/decreased o2 sats on exertion'\n",
      " 'dyspnea/decreased o2 saturations '\n",
      " 'empirical treatmen of acute exacerbation'\n",
      " 'empirical treatment of symptoms of acute exacerbations' 'exacerbation'\n",
      " 'exacerbation ' 'exacerbation of ipf' 'fibrosis' 'gerd' 'gerd/cough'\n",
      " 'hypoxemia' 'hypoxemmia' 'hypoxic respiratory failure'\n",
      " 'idiopathic pulmonary fibrosis' 'idiopathic thrombocytopenia' 'iipf'\n",
      " 'ild' 'ild exacerbation' 'ild flare' 'increase to 10 from 4-6'\n",
      " 'increased cough' 'increased dyspnea' 'ipf' 'ipf '\n",
      " 'ipf acute exacerbation' 'ipf desaturation' 'ipf dyspnea'\n",
      " 'ipf exacerbation' 'ipf exacerbation ' 'ipf flare' 'ipf progression'\n",
      " 'ipf, dyspnea' 'ipf/ sob' 'ipf/copd' 'ipr' 'low oxygenation'\n",
      " 'lower respiratory tract infection' 'lung condition' 'lung disease'\n",
      " 'lung infection' 'mild copd exacerbation' 'mild ild flare'\n",
      " 'mild ipf flare' 'mild ipf flare with component of decompensating chf'\n",
      " 'mild ipf flare with decompensating'\n",
      " 'mild ipf flare with decompensating chf' 'o2 desaturation on exertion'\n",
      " 'obstructive sleep apnea' 'pf increased cough' 'pneumonia'\n",
      " 'possible exacerbation of chronic bronchitis' 'possible ild flare'\n",
      " 'possible ipf flare +/- bronchial infection' 'possible mild ild flare'\n",
      " 'possible mild ipf flare' 'possible respiratory infection'\n",
      " 'preventative measures' 'probable mild ipf exacerbation' 'prophylactic'\n",
      " 'prophylaxis' 'pulmonary fibrosis ' 'pulmonary suprainfection'\n",
      " 'query mild ipf flare' 'resp.tract infection' 'respiratory infection'\n",
      " 'respiratory tract infection' 'rhinitis' 'right sided heart failure'\n",
      " 'sarcoidosis' 'short of breath' 'shortness of breath'\n",
      " 'shortness of breath exacerbation' 'sob' 'sob/increased mucous'\n",
      " 'steroid responsive disease' 'thrombocytopenia' 'to control phlegm'\n",
      " 'upper resp. tract infection' 'upper respiratory tract infection'\n",
      " 'wheeze']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"G:\\My Drive\\Portfolio\\Esbriet\\Publications\\\\2019 ATS\\\\2019ATS_analysis\\INSPIRATION PLUS additional analysis\\data cleaning instructions\")\n",
    "# os.getcwd()\n",
    "\n",
    "ipf_meds = pd.read_csv('Ipf_meds_indication_DF.csv')\n",
    "\n",
    "ipf_meds.columns\n",
    "print(ipf_meds.shape)\n",
    "\n",
    "unique_indication = ipf_meds['Indication'].unique()\n",
    "print(unique_indication)\n",
    "# len(unique_indication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         state     pop\n",
      "CA  California  1000.0\n",
      "TX       Texas     NaN\n",
      "         state     pop   3\n",
      "CA  California  1000.0 NaN\n",
      "TX       Texas     NaN NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX</td>\n",
       "      <td>5678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State   Pop\n",
       "0    CA  1234\n",
       "1    TX  5678"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(np.nan)\n",
    "state = pd.Series({'CA':'California', 'TX': 'Texas'})\n",
    "pop = pd.Series({'CA': 1e3, 'TX': None})\n",
    "df = pd.DataFrame({'state':state,'pop':pop})\n",
    "print(df)\n",
    "\n",
    "df[pd.notnull(df['pop'])]\n",
    "df[pd.isnull(df['pop'])]\n",
    "\n",
    "df.dropna(axis = 0)\n",
    "df.dropna(axis = 1)\n",
    "\n",
    "df[3] = np.NaN\n",
    "print(df)\n",
    "\n",
    "DF = pd.DataFrame({'State': ['CA', 'TX'], 'Pop': [1234, 5678]})\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "ls = np.linspace(-1, 11)\n",
    "print(len(ls))\n",
    "# np.linspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "counts = pd.read_csv('FremontBridge.csv', index_col='Date', parse_dates=True)\n",
    "weather = pd.read_csv('data/BicycleWeather.csv', index_col='DATE', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fremont Bridge East Sidewalk</th>\n",
       "      <th>Fremont Bridge West Sidewalk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-02</th>\n",
       "      <td>757.0</td>\n",
       "      <td>724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-03</th>\n",
       "      <td>624.0</td>\n",
       "      <td>649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>1138.0</td>\n",
       "      <td>1815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>1185.0</td>\n",
       "      <td>1869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>829.0</td>\n",
       "      <td>1418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>555.0</td>\n",
       "      <td>950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08</th>\n",
       "      <td>693.0</td>\n",
       "      <td>1183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-09</th>\n",
       "      <td>652.0</td>\n",
       "      <td>677.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-10</th>\n",
       "      <td>738.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-11</th>\n",
       "      <td>1078.0</td>\n",
       "      <td>1689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>829.0</td>\n",
       "      <td>1380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-13</th>\n",
       "      <td>1133.0</td>\n",
       "      <td>1906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-14</th>\n",
       "      <td>1186.0</td>\n",
       "      <td>1894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-15</th>\n",
       "      <td>1184.0</td>\n",
       "      <td>1837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-16</th>\n",
       "      <td>810.0</td>\n",
       "      <td>1030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-17</th>\n",
       "      <td>1036.0</td>\n",
       "      <td>1198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-18</th>\n",
       "      <td>1618.0</td>\n",
       "      <td>2698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-19</th>\n",
       "      <td>1897.0</td>\n",
       "      <td>3053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-20</th>\n",
       "      <td>1817.0</td>\n",
       "      <td>3014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-21</th>\n",
       "      <td>1444.0</td>\n",
       "      <td>2535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-22</th>\n",
       "      <td>1179.0</td>\n",
       "      <td>1876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-23</th>\n",
       "      <td>845.0</td>\n",
       "      <td>974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-24</th>\n",
       "      <td>817.0</td>\n",
       "      <td>889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>1114.0</td>\n",
       "      <td>1843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>2302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>1451.0</td>\n",
       "      <td>2339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28</th>\n",
       "      <td>1455.0</td>\n",
       "      <td>2335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29</th>\n",
       "      <td>1420.0</td>\n",
       "      <td>2168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-30</th>\n",
       "      <td>1239.0</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>1134.0</td>\n",
       "      <td>1230.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5963 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fremont Bridge East Sidewalk  Fremont Bridge West Sidewalk\n",
       "Date                                                                  \n",
       "2002-12-03                           NaN                           NaN\n",
       "2002-12-04                           NaN                           NaN\n",
       "2002-12-05                           NaN                           NaN\n",
       "2002-12-06                           NaN                           NaN\n",
       "2002-12-07                           NaN                           NaN\n",
       "2002-12-08                           NaN                           NaN\n",
       "2002-12-09                           NaN                           NaN\n",
       "2002-12-10                           NaN                           NaN\n",
       "2002-12-11                           NaN                           NaN\n",
       "2002-12-12                           NaN                           NaN\n",
       "2002-12-13                           NaN                           NaN\n",
       "2002-12-14                           NaN                           NaN\n",
       "2002-12-15                           NaN                           NaN\n",
       "2002-12-16                           NaN                           NaN\n",
       "2002-12-17                           NaN                           NaN\n",
       "2002-12-18                           NaN                           NaN\n",
       "2002-12-19                           NaN                           NaN\n",
       "2002-12-20                           NaN                           NaN\n",
       "2002-12-21                           NaN                           NaN\n",
       "2002-12-22                           NaN                           NaN\n",
       "2002-12-23                           NaN                           NaN\n",
       "2002-12-24                           NaN                           NaN\n",
       "2002-12-25                           NaN                           NaN\n",
       "2002-12-26                           NaN                           NaN\n",
       "2002-12-27                           NaN                           NaN\n",
       "2002-12-28                           NaN                           NaN\n",
       "2002-12-29                           NaN                           NaN\n",
       "2002-12-30                           NaN                           NaN\n",
       "2002-12-31                           NaN                           NaN\n",
       "2003-01-01                           NaN                           NaN\n",
       "...                                  ...                           ...\n",
       "2019-03-02                         757.0                         724.0\n",
       "2019-03-03                         624.0                         649.0\n",
       "2019-03-04                        1138.0                        1815.0\n",
       "2019-03-05                        1185.0                        1869.0\n",
       "2019-03-06                         829.0                        1418.0\n",
       "2019-03-07                         555.0                         950.0\n",
       "2019-03-08                         693.0                        1183.0\n",
       "2019-03-09                         652.0                         677.0\n",
       "2019-03-10                         738.0                         730.0\n",
       "2019-03-11                        1078.0                        1689.0\n",
       "2019-03-12                         829.0                        1380.0\n",
       "2019-03-13                        1133.0                        1906.0\n",
       "2019-03-14                        1186.0                        1894.0\n",
       "2019-03-15                        1184.0                        1837.0\n",
       "2019-03-16                         810.0                        1030.0\n",
       "2019-03-17                        1036.0                        1198.0\n",
       "2019-03-18                        1618.0                        2698.0\n",
       "2019-03-19                        1897.0                        3053.0\n",
       "2019-03-20                        1817.0                        3014.0\n",
       "2019-03-21                        1444.0                        2535.0\n",
       "2019-03-22                        1179.0                        1876.0\n",
       "2019-03-23                         845.0                         974.0\n",
       "2019-03-24                         817.0                         889.0\n",
       "2019-03-25                        1114.0                        1843.0\n",
       "2019-03-26                        1440.0                        2302.0\n",
       "2019-03-27                        1451.0                        2339.0\n",
       "2019-03-28                        1455.0                        2335.0\n",
       "2019-03-29                        1420.0                        2168.0\n",
       "2019-03-30                        1239.0                        1298.0\n",
       "2019-03-31                        1134.0                        1230.0\n",
       "\n",
       "[5963 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts.head()\n",
    "counts.resample('d').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-01-02    1\n",
       "2012-01-16    1\n",
       "2012-02-20    1\n",
       "2012-05-28    1\n",
       "2012-07-04    1\n",
       "2012-09-03    1\n",
       "2012-10-08    1\n",
       "2012-11-12    1\n",
       "2012-11-22    1\n",
       "2012-12-25    1\n",
       "2013-01-01    1\n",
       "2013-01-21    1\n",
       "2013-02-18    1\n",
       "2013-05-27    1\n",
       "2013-07-04    1\n",
       "2013-09-02    1\n",
       "2013-10-14    1\n",
       "2013-11-11    1\n",
       "2013-11-28    1\n",
       "2013-12-25    1\n",
       "2014-01-01    1\n",
       "2014-01-20    1\n",
       "2014-02-17    1\n",
       "2014-05-26    1\n",
       "2014-07-04    1\n",
       "2014-09-01    1\n",
       "2014-10-13    1\n",
       "2014-11-11    1\n",
       "2014-11-27    1\n",
       "2014-12-25    1\n",
       "2015-01-01    1\n",
       "2015-01-19    1\n",
       "2015-02-16    1\n",
       "2015-05-25    1\n",
       "2015-07-03    1\n",
       "2015-09-07    1\n",
       "2015-10-12    1\n",
       "2015-11-11    1\n",
       "2015-11-26    1\n",
       "2015-12-25    1\n",
       "2016-01-01    1\n",
       "Name: holiday, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays('2012', '2016')\n",
    "pd.Series(1, index=holidays, name='holiday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `sklearn.datasets.make_moons` not found.\n"
     ]
    }
   ],
   "source": [
    "sklearn.datasets.make_moons?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
